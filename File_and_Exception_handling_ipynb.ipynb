{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBBgTLw1qM7Q"
      },
      "outputs": [],
      "source": [
        "#ASSIGNMENT - Files & Exceptional Handling\n",
        "\n",
        "#Q1) Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "#multiprocessing is a better choice.\n",
        "\n",
        "#Multithreading and multiprocessing are both techniques used to achieve parallelism and improve performance in applications. However, they are suited for different scenarios based on how the tasks are structured and the system's resources. Here's a breakdown of when multithreading is preferable and when multiprocessing is a better choice\n",
        "#Scenarios Where Multithreading is Preferable:\n",
        "\n",
        "#1)I/O-Bound Tasks:\n",
        "#Multithreading excels when the application spends a lot of time waiting for I/O operations, such as reading from files, database queries, or network requests.\n",
        "#Threads can continue working on other tasks while one is waiting for I/O to complete, allowing better use of time and resources.\n",
        "#Example: A web server handling many client requests simultaneously, where each thread is waiting for the network to respond, not the CPU.\n",
        "\n",
        "#2)Low Memory Overhead:\n",
        "#Threads share the same memory space, so multithreading is more memory-efficient than multiprocessing.\n",
        "#If the tasks require frequent sharing of data and resources, multithreading can avoid the overhead of duplicating memory and communication between processes.\n",
        "#Example: Applications with shared state, such as GUI applications or certain game engines, where frequent data access is needed by all threads.\n",
        "\n",
        "#3)Lightweight Tasks:\n",
        "#When the tasks to be parallelized are relatively lightweight and don’t require heavy CPU usage, threading is more efficient.\n",
        "#Example: A real-time data aggregation service that collects metrics but doesn’t perform heavy computations on them.\n",
        "\n",
        "#4)Concurrency, Not Parallelism:\n",
        "#When the goal is to achieve concurrency (managing multiple tasks at once without necessarily running them simultaneously), threads are better. This is useful in event-driven applications like UI programs where responsiveness is critical.\n",
        "#Example: A desktop application that can handle user input while simultaneously performing background tasks.\n",
        "\n",
        "#5)Environments with a Global Interpreter Lock (GIL):\n",
        "#In Python, due to the GIL, multithreading can only use one CPU core at a time. However, this isn't a bottleneck for I/O-bound applications where CPU-bound tasks are minimal.\n",
        "\n",
        "#Scenarios Where Multiprocessing is a Better Choice:\n",
        "#1)CPU-Bound Tasks:\n",
        "#Multiprocessing is ideal for CPU-bound tasks where you need to fully utilize multiple CPU cores. In these tasks, the main bottleneck is the CPU’s processing power.\n",
        "#Each process in multiprocessing runs independently on its own core, bypassing the Global Interpreter Lock (GIL) in languages like Python.\n",
        "#Example: Computationally intensive tasks like video rendering, scientific simulations, machine learning model training, or data analysis.\n",
        "\n",
        "#2)Heavy Memory Use and Isolation:\n",
        "#Each process has its own memory space, so multiprocessing is better when tasks require isolation, such as preventing memory sharing to avoid conflicts.\n",
        "#Processes don't share memory unless explicitly defined (through inter-process communication), reducing the risk of race conditions.\n",
        "#Example: Running separate instances of large programs (like a web browser spawning multiple independent processes for tabs to prevent crashes from propagating).\n",
        "\n",
        "#3)Scaling Across Multiple CPUs/Cores:\n",
        "#When the system has multiple cores, multiprocessing allows true parallelism, with each process running independently on different cores.\n",
        "#Example: Image processing software that needs to apply filters to thousands of images at once or numerical simulations that require distributing workloads across many processors.\n",
        "\n",
        "#4)Avoiding the GIL in Python:\n",
        "#In Python, the Global Interpreter Lock (GIL) limits the ability of threads to execute Python bytecode in parallel. If you need to bypass the GIL to leverage multiple CPU cores for computational tasks, multiprocessing is the better choice.\n",
        "#Example: Running complex mathematical computations where each part of the computation is split across multiple processes.\n",
        "\n",
        "#5)Fault tolerance:\n",
        "#If you need strong fault isolation where an error in one task should not affect other tasks, multiprocessing is preferable because each process operates in its own memory space.\n",
        "#Example: A critical system where different modules (e.g., logging, monitoring, and processing) run in isolation to ensure that failure in one module doesn’t bring down the entire system.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2) Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "\n",
        "#A process pool is a programming abstraction that allows for efficient management of multiple processes, especially when working with a large number of tasks. It is essentially a pool of worker processes that are created once and then used to execute tasks concurrently. This approach reduces the overhead associated with creating and destroying processes repeatedly.\n",
        "#Key Features of a Process Pool:\n",
        "\n",
        "#1)Pre-allocated Pool of Processes:\n",
        "#Instead of spawning a new process for each task, a fixed number of processes are created ahead of time (in the \"pool\"). These processes are reused to handle multiple tasks.\n",
        "#The pool size is typically set to match the number of available CPU cores or some other optimal number based on the system's capacity.\n",
        "\n",
        "#2)Task Distribution:\n",
        "#The process pool manages the distribution of tasks to the worker processes. When a task is submitted, the pool assigns it to an available process. If all processes are busy, the task waits in a queue until a process becomes free.\n",
        "#This avoids the overhead of process creation/destruction for each task and ensures tasks are handled as soon as a worker becomes available.\n",
        "\n",
        "#3)Concurrency and Parallelism:\n",
        "#The pool allows for concurrent execution of tasks in multiple processes, enabling the program to take full advantage of multi-core systems for CPU-bound tasks.\n",
        "#For example, a pool of 4 processes can handle 4 tasks simultaneously on a 4-core CPU, allowing efficient parallel processing.\n",
        "\n",
        "#4)Task Queuing:\n",
        "#Tasks that cannot be handled immediately are placed in a queue, which the pool manages. As soon as a worker becomes available, the next task in the queue is assigned to it.\n",
        "#This queue-based system ensures tasks are not lost and are handled in a structured manner.\n",
        "\n",
        "#5)Simplified Process Management:\n",
        "#A process pool abstracts away the complexities of managing individual processes. Instead of manually creating, terminating, and handling communication between processes, the pool handles these tasks automatically.\n",
        "#This reduces the risk of resource leaks and simplifies error handling, such as terminating stuck or hung processes.\n",
        "\n",
        "#Benefits of Using a Process Pool:\n",
        "#1)Reduced Overhead:\n",
        "#Creating a process is resource-intensive. By reusing processes from the pool, the overhead of constantly starting and stopping processes is avoided, leading to faster execution times, especially in scenarios with many short-lived tasks.\n",
        "#2)Efficient Use of System Resources:\n",
        "#A process pool helps match the number of processes to the system’s resources (e.g., the number of CPU cores), preventing the system from being overwhelmed by too many processes running simultaneously. It avoids the issue of overcommitting CPU or memory resources.\n",
        "#3)Load Balancing:\n",
        "#The process pool evenly distributes tasks across the available worker processes, ensuring that no single process is overwhelmed with too many tasks while others remain idle.\n",
        "#4)Automatic Task Management:\n",
        "#The pool handles the complexity of managing tasks and processes, including queuing tasks and assigning them to processes. It abstracts the user from the nitty-gritty details of inter-process communication (IPC), synchronization, and error handling.\n",
        "\n",
        "#Process Pool in Python:\n",
        "#In Python, the multiprocessing.Pool class provides a simple way to create a process pool:\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_task(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with Pool(processes=4) as pool:  # Create a pool with 4 processes\n",
        "        results = pool.map(process_task, [1, 2, 3, 4, 5])\n",
        "        print(results)  # Output: [1, 4, 9, 16, 25]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFfmlfl9tUfq",
        "outputId": "d9b52db2-83bf-4b81-8617-7cba1bacd0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here, the process pool creates 4 processes and distributes the process_task function across them. The pool.map() method submits multiple tasks to the pool and waits for their results.\n",
        "\n"
      ],
      "metadata": {
        "id": "OAWKtVK4vvu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3) Explain what multiprocessing is and why it is used in Python programs.\n",
        "\n",
        "#Multiprocessing is a programming technique where multiple independent processes are executed simultaneously, allowing a program to perform parallel execution. Each process runs in its own memory space, and they can run independently on multiple CPU cores. In Python, multiprocessing is particularly useful for overcoming the limitations of the Global Interpreter Lock (GIL), which restricts multi-threaded programs from fully utilizing multiple cores for CPU-bound tasks.\n",
        "#Why Multiprocessing is Used in Python Programs:\n",
        "#1)To Achieve True Parallelism:\n",
        "#Python's Global Interpreter Lock (GIL): Python’s GIL ensures that only one thread can execute Python bytecode at a time, even in a multi-threaded program. This makes it difficult to achieve true parallelism in CPU-bound tasks using threads.\n",
        "#Multiprocessing bypasses the GIL: Since each process in Python runs in its own memory space with its own Python interpreter, multiprocessing allows multiple processes to run simultaneously on different CPU cores, achieving real parallel execution. This makes it ideal for CPU-bound tasks (tasks that require intensive computation, such as numerical simulations, video encoding, or image processing).\n",
        "\n",
        "#2)Utilizing Multiple CPU Cores:\n",
        "#In modern systems, most CPUs have multiple cores, allowing them to handle multiple tasks at the same time. Multiprocessing allows Python programs to take full advantage of these multi-core CPUs.\n",
        "#While a single-threaded Python program can only run on one core, multiprocessing enables a program to distribute its workload across all available cores, improving performance.\n",
        "\n",
        "#3)Isolation Between Processes:\n",
        "#Each process in a multiprocessing environment has its own memory space, which means they do not share global variables. This isolation reduces the chances of errors caused by shared state, race conditions, or memory corruption, which are common challenges in multi-threaded programs.\n",
        "#This isolation ensures that if one process crashes, it won’t affect the others.\n",
        "\n",
        "#4)Handling CPU-Bound Tasks:\n",
        "#CPU-bound tasks are tasks where the bottleneck is the CPU’s processing power (e.g., complex calculations, data crunching, or scientific simulations). Multiprocessing excels in these scenarios by distributing the work across multiple processes, allowing different parts of the task to be processed concurrently.\n",
        "#Example: Dividing a large dataset and processing chunks of it in parallel using multiple processes.\n",
        "\n",
        "#5)Improving Performance for Heavy Computations:\n",
        "#In Python, heavy computational tasks can be slowed down by the limitations of the interpreter and the GIL. By using multiprocessing, such tasks can be split into smaller, independent sub-tasks, each running in a separate process, which can lead to significant performance gains.\n",
        "#For example, when training a machine learning model or performing numerical simulations, using multiprocessing can greatly reduce the overall computation time.\n",
        "\n",
        "#How Multiprocessing is Implemented in Python:\n",
        "#Python's multiprocessing module provides a simple interface to create and manage processes. Some key components include:\n",
        "#1)Creating Processes:\n",
        "#You can create new processes using multiprocessing.Process. Each process runs independently and can execute a target function concurrently with other processes.\n",
        "from multiprocessing import Process\n",
        "\n",
        "def worker():\n",
        "    print(\"Worker process\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    p1 = Process(target=worker)\n",
        "    p1.start()\n",
        "    p1.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGdQVEVav7TB",
        "outputId": "898f382d-484d-4f02-dfd7-1e5d0c1afd28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2)Process Pool:\n",
        "#The Pool class from the multiprocessing module allows you to manage a pool of worker processes. The pool can distribute tasks to the available processes, improving performance by reusing them.\n",
        "#from multiprocessing import Pool\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with Pool(processes=4) as pool:\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "        print(results)  # Output: [1, 4, 9, 16, 25]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v56vTi4Axd_X",
        "outputId": "e882d006-a4c5-4c4d-b30d-8b52527c2f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3)Inter-Process Communication (IPC):\n",
        "#The multiprocessing module provides mechanisms like Queue, Pipe, and Manager to enable communication between processes, allowing them to exchange data safely despite their isolated memory spaces.\n",
        "#Use Cases for Multiprocessing in Python:\n",
        "\n",
        "#1)Data Processing:\n",
        "#Large datasets can be split into smaller chunks and processed in parallel using multiprocessing. This approach reduces the time it takes to complete data analysis or transformation tasks.\n",
        "\n",
        "#2)Machine Learning and AI:\n",
        "#Training models often involves heavy computations that can be parallelized across multiple processes to speed up training time, especially when handling large datasets or complex neural networks.\n",
        "\n",
        "#3)Scientific Computing:\n",
        "#In fields like physics, chemistry, or finance, simulations often involve running complex computations or models. Multiprocessing can be used to distribute these computations across several processes, allowing them to run faster.\n",
        "\n",
        "#4)Web Scraping:\n",
        "#Scraping data from websites is often limited by network latency. Multiprocessing can be used to handle multiple requests concurrently, improving the speed and efficiency of the scraping process.\n"
      ],
      "metadata": {
        "id": "y3GoJywcxpHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4) Write a Python program using multithreading where one thread adds numbers to a list, and anotherthread removes numbers from the list. Implement a mechanism to avoid race conditions usingthreading.Lock.\n",
        "\n",
        "#Here’s a Python program that demonstrates multithreading with one thread adding numbers to a list and another thread removing numbers from the list. The program uses threading.Lock to prevent race conditions, ensuring that only one thread can modify the list at a time.\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Create a lock object to avoid race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function for adding numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            number = random.randint(1, 100)\n",
        "            shared_list.append(number)\n",
        "            print(f\"Added {number} to the list.\")\n",
        "        time.sleep(0.1)  # Additional delay to simulate other work\n",
        "\n",
        "# Function for removing numbers from the list\n",
        "def remove_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            if shared_list:\n",
        "                removed_number = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_number} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, cannot remove.\")\n",
        "        time.sleep(0.1)  # Additional delay to simulate other work\n",
        "\n",
        "# Create the threads for adding and removing numbers\n",
        "add_thread = threading.Thread(target=add_numbers)\n",
        "remove_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start the threads\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBGZ7yI5ymBZ",
        "outputId": "c95da959-49ba-451d-fca9-d5a83606365b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List is empty, cannot remove.\n",
            "Added 20 to the list.\n",
            "Removed 20 from the list.\n",
            "Added 69 to the list.\n",
            "Removed 69 from the list.\n",
            "List is empty, cannot remove.\n",
            "Added 24 to the list.\n",
            "Added 14 to the list.\n",
            "Removed 24 from the list.\n",
            "Added 65 to the list.\n",
            "Added 51 to the list.\n",
            "Removed 14 from the list.\n",
            "Added 69 to the list.\n",
            "Removed 65 from the list.\n",
            "Added 71 to the list.\n",
            "Added 83 to the list.\n",
            "Removed 51 from the list.\n",
            "Added 58 to the list.\n",
            "Removed 69 from the list.\n",
            "Removed 71 from the list.\n",
            "Final list: [83, 58]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5)Describe the methods and tools available in Python for safely sharing data\n",
        "# between threads and processes.\n",
        "#Ans.)In Python, safely sharing data between threads and processes is crucial to avoid race conditions, data corruption, and synchronization issues. Python provides several methods and tools specifically designed for safe data sharing between threads (which share memory) and processes (which do not share memory and have separate address spaces). Here's an overview of these methods and tools:\n",
        "#For Sharing Data Between Threads:\n",
        "#1)1. Locks (threading.Lock)\n",
        "#A lock is the most basic synchronization primitive provided by the threading module. It ensures that only one thread can access a shared resource at a time, preventing race conditions.\n",
        "#You can use a Lock to protect critical sections of code where shared resources are accessed or modified.\n",
        "#example:import threading\n",
        "\n",
        "shared_data = 0\n",
        "lock = threading.Lock()\n",
        "\n",
        "def increment():\n",
        "    global shared_data\n",
        "    with lock:  # Acquires lock before modifying shared data\n",
        "        shared_data += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "NOeQdMJzy_j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. RLocks (threading.RLock)\n",
        "\n",
        "#Reentrant Lock (RLock) allows a thread that has already acquired the lock to re-acquire it without causing a deadlock. This is useful when a thread needs to acquire a lock multiple times within the same task.\n",
        "lock = threading.RLock()\n"
      ],
      "metadata": {
        "id": "1MM2fGgxzlPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Condition Variables (threading.Condition)\n",
        "#A condition variable allows threads to wait for certain conditions to be met before continuing execution. It’s used with a lock and helps with synchronization between threads.\n",
        "#A thread can wait() for a condition, and another thread can notify() it once the condition is met, which allows for complex synchronization patterns.\n",
        "#Example:\n",
        "condition = threading.Condition()\n",
        "\n",
        "#4. Semaphores (threading.Semaphore)\n",
        "#A semaphore allows a fixed number of threads to access a shared resource simultaneously. It’s like a counter where acquire() decrements the counter and release() increments it.\n",
        "semaphore = threading.Semaphore(3)  # Allow up to 3 threads to access the resource\n",
        "\n",
        "#5.  Event (threading.Event)\n",
        "#An event is a synchronization primitive that allows threads to communicate by signaling an occurrence of a condition. One thread can wait for an event, and another thread can set the event, allowing the waiting thread to continue.\n",
        "event = threading.Event()\n",
        "\n",
        "#6. Queues (queue.Queue):\n",
        "#A queue is a thread-safe data structure provided by the queue module, used for passing data between threads. Queues handle synchronization internally, meaning multiple threads can safely put() and get() data from the queue without any additional locks.\n",
        "#Queues are often used in producer-consumer scenarios where one or more threads produce data and one or more threads consume it.\n",
        "\n",
        "from queue import Queue\n",
        "q = Queue()\n",
        "\n",
        "#For Sharing Data Between Processes:\n",
        "#Since processes have separate memory spaces, sharing data between processes is more challenging. The multiprocessing module provides several tools for safely sharing data between processes, which include mechanisms like shared memory and inter-process communication (IPC).\n",
        "#1. Queues (multiprocessing.Queue)\n",
        "#A queue in the multiprocessing module is similar to queue.Queue, but it is designed for process-safe data sharing. It allows data to be passed between processes using a producer-consumer pattern.\n",
        "#The queue operates with inter-process communication (IPC), making it a simple way to share data between processes.\n",
        "\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def producer(queue):\n",
        "    queue.put(\"Data\")\n",
        "\n",
        "def consumer(queue):\n",
        "    data = queue.get()\n",
        "\n",
        "q = Queue()\n",
        "p1 = Process(target=producer, args=(q,))\n",
        "p2 = Process(target=consumer, args=(q,))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F8NK-4Pu0A4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Pipes (multiprocessing.Pipe)\n",
        "#Pipes allow two processes to communicate by sending data back and forth. A pipe is a one-way or duplex communication channel between two processes.\n",
        "#Pipes are typically used when communication is needed between only two processes.\n",
        "\n",
        "from multiprocessing import Pipe\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "parent_conn.send(\"Hello\")\n",
        "print(child_conn.recv())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYH4rr5s1dC-",
        "outputId": "7b138815-f513-4c1e-c837-573225b20e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Shared Memory (multiprocessing.Value and multiprocessing.Array)\n",
        "#Shared memory allows processes to share data directly. multiprocessing.Value and multiprocessing.Array are two such tools that allow a simple data type or an array of data to be shared across processes.\n",
        "#Both Value and Array allow safe access to shared data using locks under the hood.\n",
        "\n",
        "from multiprocessing import Value\n",
        "\n",
        "shared_value = Value('i', 0)  # 'i' is for integer\n",
        "\n",
        "#4. Manager (multiprocessing.Manager)\n",
        "#A Manager allows for the sharing of more complex data structures like lists, dictionaries, or even objects between processes. The Manager runs a server process that manages shared objects, and processes communicate with it using proxies.\n",
        "#This is useful for sharing mutable data structures like lists or dictionaries across multiple processes.\n",
        "\n",
        "#Summary:\n",
        "\n",
        "#For locks:\n",
        "#Locks, RLocks, Condition Variables, Semaphores, Events, and Queues are used for safely sharing data and coordinating thread execution within the same memory space. These tools ensure that threads can communicate and synchronize safely while preventing race conditions.\n",
        "\n",
        "#For Process:\n",
        "#Queues, Pipes, Shared Memory (Value and Array), Managers, and Locks are used for sharing data between separate processes that don’t share memory. Inter-process communication (IPC) is achieved via tools like pipes and queues, while shared memory objects allow limited data sharing.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lfmegxeo1nhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6) Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
        "\n",
        "#Handling exceptions in concurrent programs is crucial because concurrency introduces additional complexity compared to sequential programs. Without proper exception handling, the entire program or certain critical tasks could fail silently, leading to unpredictable behavior, data corruption, deadlocks, or resource leaks. Here’s why exception handling is important and the techniques available for managing exceptions in concurrent programs.\n",
        "#Why Exception Handling is Crucial in Concurrent Programs:\n",
        "#Preventing Program Crashes:\n",
        "\n",
        "#In concurrent programs (whether using threads or processes), a single unhandled exception in one thread or process can cause that thread or process to terminate unexpectedly. If critical tasks are assigned to that thread or process, the failure could lead to incomplete operations, resource leaks, or even program crashes.\n",
        "#Avoiding Silent Failures:\n",
        "\n",
        "#Some threads or processes might fail silently without notifying the main program, especially when tasks are handled asynchronously. This can leave the program in an inconsistent state or cause the program to continue operating without realizing that part of the task has failed.\n",
        "#Ensuring Proper Cleanup:\n",
        "\n",
        "#When exceptions are not handled, resources such as file handles, network connections, or locks might not be released properly. In concurrent programs, this can lead to resource contention, deadlocks, or memory leaks. Properly handling exceptions ensures that resources are cleaned up correctly (e.g., releasing locks or closing file handles).\n",
        "#Handling Deadlocks and Race Conditions:\n",
        "\n",
        "#In concurrent programming, exceptions could occur due to deadlocks (e.g., when two threads/processes wait indefinitely for each other to release a resource) or race conditions. Handling such exceptions allows the program to recover gracefully instead of crashing or stalling.\n",
        "#Maintaining Program Consistency:\n",
        "\n",
        "#Concurrent programs often deal with shared data and resources. An exception occurring during a critical section (e.g., while modifying shared data) could leave the data in an inconsistent or corrupted state. By handling exceptions, you can roll back operations, release resources, or restore consistent states.\n",
        "\n",
        "#Techniques for Handling Exceptions in Concurrent Programs:\n",
        "#Python provides several mechanisms and techniques to handle exceptions safely and effectively in concurrent programming, whether using threads or multiprocessing. Below are some of the common techniques:\n",
        "\n",
        "#1. Handling Exceptions in Threads\n",
        "#In multithreaded programs, handling exceptions is slightly more complicated than in sequential code because exceptions raised in one thread do not automatically propagate to the main thread.\n",
        "\n",
        "#a) Try-Except Block Inside the Thread\n",
        "#The most straightforward way to handle exceptions in threads is to wrap the thread’s work in a try-except block. This ensures that each thread handles its own exceptions and can clean up resources or notify other threads if necessary.\n",
        "\n",
        "import threading\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        # Simulate some work that may raise an exception\n",
        "        result = 1 / 0\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=task)\n",
        "thread.start()\n",
        "thread.join()  # Wait for the thread to complete\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFHt092k2XOq",
        "outputId": "63054314-9a3b-4813-f0eb-b91271e4253b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception occurred in thread: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b) Using Thread.join() with Exception Tracking\n",
        "#The main thread can keep track of exceptions raised in worker threads by storing the exceptions and then handling them after the threads have finished executing. This method ensures that exceptions don’t go unnoticed.\n",
        "import threading\n",
        "\n",
        "def task(result):\n",
        "    try:\n",
        "        result[\"value\"] = 1 / 0  # This will raise an exception\n",
        "    except Exception as e:\n",
        "        result[\"exception\"] = e\n",
        "\n",
        "result = {}\n",
        "thread = threading.Thread(target=task, args=(result,))\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "if \"exception\" in result:\n",
        "    print(f\"Exception occurred: {result['exception']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3osRQ413qQ_",
        "outputId": "0b07013e-9993-400e-eb8b-8dcfa503c643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception occurred: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#c. Thread-Safe Queues to Pass Exceptions\n",
        "#Another technique is to use a queue to pass exceptions from worker threads to the main thread, where they can be handled properly.\n",
        "import threading\n",
        "import queue\n",
        "\n",
        "def task(q):\n",
        "    try:\n",
        "        # Simulate work that can raise an exception\n",
        "        result = 1 / 0\n",
        "    except Exception as e:\n",
        "        q.put(e)\n",
        "\n",
        "q = queue.Queue()\n",
        "thread = threading.Thread(target=task, args=(q,))\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "try:\n",
        "    exception = q.get_nowait()\n",
        "    print(f\"Exception occurred: {exception}\")\n",
        "except queue.Empty:\n",
        "    print(\"No exception occurred.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxE89rcm3z2e",
        "outputId": "5eb41d7f-4f0b-4274-8731-a173bb5d5e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception occurred: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Handling Exceptions in Multiprocessing\n",
        "#When using multiprocessing, processes run in separate memory spaces, and exceptions raised in child processes do not propagate directly to the main process. However, there are techniques to capture and handle these exceptions.\n",
        "\n",
        "#a) Try-Except Block Inside the Process\n",
        "#Similar to threads, you can handle exceptions inside the worker processes by wrapping the code in a try-except block.\n",
        "from multiprocessing import Process\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        result = 1 / 0\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in process: {e}\")\n",
        "\n",
        "process = Process(target=task)\n",
        "process.start()\n",
        "process.join()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnda9P2e4HO6",
        "outputId": "ef6405f0-5c9b-4081-ded9-60d35a3f5bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in process: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b. Using Multiprocessing Queues to Handle Exceptions\n",
        "#A multiprocessing.Queue can be used to pass exceptions from worker processes to the main process. This allows the main process to be notified and handle any exceptions that occur in child processes.\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def task(q):\n",
        "    try:\n",
        "        result = 1 / 0\n",
        "    except Exception as e:\n",
        "        q.put(e)\n",
        "\n",
        "q = Queue()\n",
        "process = Process(target=task, args=(q,))\n",
        "process.start()\n",
        "process.join()\n",
        "\n",
        "if not q.empty():\n",
        "    exception = q.get()\n",
        "    print(f\"Exception in process: {exception}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zxEoven4Qof",
        "outputId": "c041cd7c-231d-4e91-f107-21ce7ce47185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in process: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Clean-Up Using finally Blocks\n",
        "#Whether you're working with threads or processes, it's important to clean up resources properly, such as releasing locks, closing files, or network connections. Using a finally block ensures that clean-up code is executed, even if an exception occurs.\n",
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        lock.acquire()\n",
        "        # Simulate some work\n",
        "        result = 1 / 0  # Raise an exception\n",
        "    finally:\n",
        "        lock.release()  # Always release the lock\n",
        "\n",
        "thread = threading.Thread(target=task)\n",
        "thread.start()\n",
        "thread.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9v9bQ2U4apP",
        "outputId": "30991ed0-0e65-410f-e026-c5a65c90c7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-21 (task):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-23-b8f98f494168>\", line 11, in task\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q7.Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "#Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "\n",
        "#Here’s a Python program that calculates the factorial of numbers from 1 to 10 concurrently using a thread pool. The program uses concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial of a number\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main code\n",
        "if __name__ == \"__main__\":\n",
        "    # List of numbers for which we want to calculate the factorial\n",
        "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
        "\n",
        "    # Create a ThreadPoolExecutor to manage threads\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        # Submit the factorial tasks to the thread pool\n",
        "        results = list(executor.map(factorial, numbers))\n",
        "\n",
        "    # Print the results\n",
        "    for number, result in zip(numbers, results):\n",
        "        print(f\"Factorial of {number} is {result}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ooVKfOD42Ru",
        "outputId": "6ee243b9-cc83-47b8-f3a5-5c87005583c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating factorial of 1Calculating factorial of 2\n",
            "\n",
            "Calculating factorial of 3\n",
            "Calculating factorial of 4\n",
            "Calculating factorial of 5\n",
            "Calculating factorial of 6\n",
            "Calculating factorial of 7Calculating factorial of 8Calculating factorial of 9\n",
            "\n",
            "\n",
            "Calculating factorial of 10\n",
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "#parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "#processes).\n",
        "\n",
        "# Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "#parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "#processes).\n",
        "\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure computation time with different pool sizes\n",
        "def compute_squares_with_pool_size(pool_size, numbers):\n",
        "    print(f\"\\nUsing a pool of {pool_size} processes\")\n",
        "\n",
        "    # Measure start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a Pool of processes\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        # Perform parallel computation of squares\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "    # Measure end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Print results and computation time\n",
        "    print(f\"Squares: {results}\")\n",
        "    print(f\"Time taken with pool size {pool_size}: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Main code\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
        "\n",
        "    # Test with different pool sizes\n",
        "    for pool_size in [2, 4, 8]:\n",
        "        compute_squares_with_pool_size(pool_size, numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldzjx_yn5Ljt",
        "outputId": "4645286a-4295-4c08-faa5-4b9f78b31333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using a pool of 2 processes\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with pool size 2: 0.0952 seconds\n",
            "\n",
            "Using a pool of 4 processes\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with pool size 4: 0.0797 seconds\n",
            "\n",
            "Using a pool of 8 processes\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with pool size 8: 0.0792 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwmarfWt5mpA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}